{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f37da56b-f033-4741-9186-5344e84b54c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Combinations by Overall Rank:\n",
      "                  Dataset                      Model           MSE  \\\n",
      "23     StandardScaler_IQR  GradientBoostingRegressor  2.504240e+09   \n",
      "19         Normalizer_IQR  GradientBoostingRegressor  2.520261e+09   \n",
      "22     StandardScaler_IQR      RandomForestRegressor  2.523651e+09   \n",
      "18         Normalizer_IQR      RandomForestRegressor  2.539994e+09   \n",
      "3   StandardScaler_ZScore  GradientBoostingRegressor  2.662289e+09   \n",
      "\n",
      "             MAE       R^2  MSE_rank  MAE_rank  R^2_rank  Total_rank  \n",
      "23  39228.714645  0.271588       1.0       1.0       6.0    2.666667  \n",
      "19  39340.376000  0.266928       2.0       4.0       9.0    5.000000  \n",
      "22  39266.381384  0.265942       3.0       3.0      10.0    5.333333  \n",
      "18  39263.755028  0.261188       4.0       2.0      12.0    6.000000  \n",
      "3   40652.725491  0.275543       7.0      12.0       1.0    6.666667  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(X_train, X_test, y_train, y_test, model):\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    y_pred = model.predict(X_test)  # Make predictions\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return mse, mae, r2\n",
    "\n",
    "datasets = {\n",
    "    'StandardScaler_ZScore': 'termproject/preprocessed_data_standardized.csv',\n",
    "    'Normalizer_ZScore': 'termproject/preprocessed_data_normalized.csv',\n",
    "    'MinMaxScaler_ZScore': 'termproject/preprocessed_data_2.csv',\n",
    "    'MinMaxScaler_LabelEncoder': 'termproject/preprocessed_data.csv',\n",
    "    'Normalizer_IQR': 'termproject/preprocessed_data_normalized_iqr.csv',\n",
    "    'StandardScaler_IQR': 'termproject/preprocessed_data_standard_iqr.csv',\n",
    "}\n",
    "\n",
    "# Define models to be used\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Evaluate each combination of dataset and model\n",
    "for dataset_name, filepath in datasets.items():\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        data = pd.read_csv(filepath)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filepath} not found.\")\n",
    "        continue\n",
    "    \n",
    "    # Separate features and target variable\n",
    "    X = data.drop(columns=['salary_in_usd'])\n",
    "    y = data['salary_in_usd']\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Evaluate each model on the dataset\n",
    "    for model_name, model in models.items():\n",
    "        mse, mae, r2 = evaluate_model(X_train, X_test, y_train, y_test, model)\n",
    "        results.append({\n",
    "            'Dataset': dataset_name,\n",
    "            'Model': model_name,\n",
    "            'MSE': mse,\n",
    "            'MAE': mae,\n",
    "            'R^2': r2\n",
    "        })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Rank each metric\n",
    "results_df['MSE_rank'] = results_df['MSE'].rank(ascending=True)  # MSE: lower is better\n",
    "results_df['MAE_rank'] = results_df['MAE'].rank(ascending=True)  # MAE: lower is better\n",
    "results_df['R^2_rank'] = results_df['R^2'].rank(ascending=False)  # R^2: higher is better\n",
    "\n",
    "# Calculate the total rank\n",
    "results_df['Total_rank'] = results_df[['MSE_rank', 'MAE_rank', 'R^2_rank']].mean(axis=1)\n",
    "\n",
    "# Select the top 5 combinations by overall rank\n",
    "top_5_overall = results_df.nsmallest(5, 'Total_rank')\n",
    "\n",
    "# Print the top 5 combinations\n",
    "print(\"Top 5 Combinations by Overall Rank:\")\n",
    "print(top_5_overall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ac9b1-4989-49b6-989f-b8929628e33f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
